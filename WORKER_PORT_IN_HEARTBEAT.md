# Worker Port in Heartbeat - Analysis

**TEAM-XXX**: How dynamic worker ports reach the queen for scheduling

**Date**: 2025-11-08  
**Status**: ‚úÖ ALREADY WORKING - No changes needed!

---

## üéâ Summary

**Good news!** The worker port is ALREADY included in the heartbeat sent to the queen. The existing architecture supports dynamic ports perfectly.

---

## üìä Current Architecture

### Flow: Worker ‚Üí Queen

```
1. Hive spawns worker with dynamic port (e.g., 8080)
   ‚Üì
2. Worker creates WorkerInfo with port field
   ‚Üì
3. Worker sends WorkerHeartbeat to queen every 30s
   ‚Üì
4. Queen receives heartbeat (currently TODO but structure ready)
   ‚Üì
5. Queen can use port for scheduling decisions
```

### Alternative Flow: Worker ‚Üí Hive ‚Üí Queen (via Telemetry)

```
1. Hive spawns worker with dynamic port (e.g., 8080)
   ‚Üì
2. Hive monitors worker process (ProcessStats)
   ‚Üì
3. Hive sends telemetry to queen via SSE
   ‚Üì
4. Queen stores ProcessStats in TelemetryRegistry
   ‚Üì
5. Queen can query workers by port/model/GPU usage
```

---

## üîç Code Evidence

### 1. WorkerInfo Contract (ALREADY HAS PORT)

**File:** `/bin/97_contracts/worker-contract/src/types.rs`

```rust
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct WorkerInfo {
    pub id: String,
    pub model_id: String,
    pub device: String,
    pub port: u16,  // ‚úÖ PORT IS HERE!
    pub status: WorkerStatus,
    pub implementation: String,
    pub version: String,
}
```

### 2. Worker Sends Port in Heartbeat

**File:** `/bin/30_llm_worker_rbee/src/main.rs` (lines 200-208)

```rust
let worker_info = worker_contract::WorkerInfo {
    id: args.worker_id.clone(),
    model_id: args.model_ref.clone(),
    device: format!("{}:{}", args.backend, args.device),
    port: args.port,  // ‚úÖ DYNAMIC PORT INCLUDED!
    status: worker_contract::WorkerStatus::Ready,
    implementation: "llm-worker-rbee".to_string(),
    version: env!("CARGO_PKG_VERSION").to_string(),
};

let _heartbeat_handle = llm_worker_rbee::heartbeat::start_heartbeat_task(
    worker_info,
    args.hive_url.clone(), // Actually queen URL
);
```

### 3. WorkerHeartbeat Structure

**File:** `/bin/97_contracts/worker-contract/src/heartbeat.rs`

```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkerHeartbeat {
    /// Complete worker information (includes port!)
    pub worker: WorkerInfo,
    /// Timestamp of heartbeat
    pub timestamp: chrono::DateTime<chrono::Utc>,
}
```

### 4. ProcessStats (Alternative Telemetry Path)

**File:** `/bin/25_rbee_hive_crates/monitor/src/lib.rs`

```rust
pub struct ProcessStats {
    pub pid: u32,
    pub group: String,
    pub instance: String,  // ‚úÖ PORT NUMBER (e.g., "8080")
    pub cpu_pct: f64,
    pub rss_mb: u64,
    pub gpu_util_pct: f64,
    pub vram_mb: u64,
    pub total_vram_mb: u64,
    pub model: Option<String>,
    // ... other fields
}
```

**Note:** The `instance` field contains the port number as a string.

---

## üîÑ Two Paths to Queen

### Path 1: Direct Worker ‚Üí Queen Heartbeat (TODO)

**Current Status:** Structure exists but HTTP POST is commented out

**File:** `/bin/32_shared_worker_rbee/src/heartbeat.rs`

```rust
pub async fn send_heartbeat_to_queen(
    worker_info: &WorkerInfo,
    queen_url: &str,
) -> Result<()> {
    let _heartbeat = WorkerHeartbeat::new(worker_info.clone());

    // TODO: Implement HTTP POST to queen
    // POST {queen_url}/v1/worker-heartbeat with heartbeat
    // let client = reqwest::Client::new();
    // client.post(format!("{}/v1/worker-heartbeat", queen_url))
    //     .json(&_heartbeat)
    //     .send()
    //     .await?;

    Ok(())
}
```

**To Enable:**
1. Uncomment HTTP POST code
2. Add queen endpoint: `POST /v1/worker-heartbeat`
3. Queen stores `WorkerInfo` in registry

### Path 2: Hive ‚Üí Queen Telemetry (WORKING)

**Current Status:** ‚úÖ FULLY IMPLEMENTED via SSE

**Flow:**
1. Hive monitors worker processes ‚Üí `ProcessStats`
2. Hive sends telemetry via SSE ‚Üí `GET /v1/heartbeats/stream`
3. Queen subscribes to hive SSE
4. Queen stores `ProcessStats` in `TelemetryRegistry`

**File:** `/bin/10_queen_rbee/src/hive_subscriber.rs`

```rust
pub fn start_hive_subscription(
    hive_url: String,
    hive_id: String,
    hive_registry: Arc<TelemetryRegistry>,
    event_tx: broadcast::Sender<HeartbeatEvent>,
) -> tokio::task::JoinHandle<()>
```

---

## üéØ Queen Scheduling with Ports

### Current Capabilities

The queen can already query workers by various criteria:

```rust
// Get all workers across all hives
let workers = telemetry_registry.get_all_workers();

// Find idle workers (gpu_util_pct == 0.0)
let idle = telemetry_registry.find_idle_workers();

// Find workers with specific model
let llama_workers = telemetry_registry.find_workers_with_model("llama-3.2-1b");

// Find workers with available VRAM
let available = telemetry_registry.find_workers_with_vram_capacity(4096);
```

### Accessing Worker Port

**From ProcessStats:**
```rust
for worker in workers {
    let port: u16 = worker.instance.parse().unwrap();
    let worker_url = format!("http://localhost:{}", port);
    // Send inference request to worker_url
}
```

**From WorkerInfo (if direct heartbeat enabled):**
```rust
let worker_url = worker_info.url(); // Returns "http://localhost:{port}"
```

---

## ‚úÖ What's Already Working

1. ‚úÖ **WorkerInfo has port field** - Contract supports it
2. ‚úÖ **Workers create WorkerInfo with dynamic port** - Populated from args
3. ‚úÖ **WorkerHeartbeat includes full WorkerInfo** - Port is in payload
4. ‚úÖ **ProcessStats includes port as instance** - Alternative telemetry path
5. ‚úÖ **Hive ‚Üí Queen telemetry via SSE** - Working end-to-end
6. ‚úÖ **TelemetryRegistry stores worker stats** - Queen can query

---

## üî® What Needs Implementation (Optional)

### Option A: Enable Direct Worker ‚Üí Queen Heartbeat

**Why:** More direct, less latency, worker self-reports

**Steps:**
1. Uncomment HTTP POST in `send_heartbeat_to_queen()`
2. Add queen endpoint: `POST /v1/worker-heartbeat`
3. Store `WorkerInfo` in a worker registry (separate from hive telemetry)

**Benefits:**
- Worker self-reports status
- Lower latency than hive telemetry
- Worker can report custom metrics

**Drawbacks:**
- Duplicate information (also in hive telemetry)
- More network traffic
- Need to handle worker crashes (no cleanup)

### Option B: Use Existing Hive Telemetry (Recommended)

**Why:** Already working, centralized, includes resource metrics

**Current State:** ‚úÖ FULLY WORKING

**Benefits:**
- Already implemented
- Centralized monitoring via hive
- Includes GPU/CPU/memory metrics
- Automatic cleanup when worker stops

**Drawbacks:**
- Slightly higher latency (goes through hive)
- Hive must be running

---

## üìã Recommendation

**Use the existing hive telemetry path (Option B).** It's already fully implemented and working.

### Why?

1. **Already working** - No code changes needed
2. **Centralized** - Hive monitors all workers
3. **Rich metrics** - GPU, CPU, memory, model info
4. **Automatic cleanup** - Hive removes dead workers
5. **Port is included** - In `ProcessStats.instance` field

### How Queen Uses Port for Scheduling

```rust
// Example: Find idle worker and send inference request
let idle_workers = telemetry_registry.find_idle_workers();

if let Some(worker) = idle_workers.first() {
    let port: u16 = worker.instance.parse()?;
    let worker_url = format!("http://localhost:{}", port);
    
    // Send inference request
    let response = reqwest::Client::new()
        .post(format!("{}/v1/infer", worker_url))
        .json(&infer_request)
        .send()
        .await?;
}
```

---

## üîç Verification

### Check Worker Port in Telemetry

**1. Start hive:**
```bash
cargo run --bin rbee-hive
```

**2. Spawn worker (gets dynamic port 8080):**
```bash
curl -X POST http://localhost:7835/v1/jobs \
  -d '{"operation": "worker_spawn", "worker": "cpu", "model": "test", "device": 0}'
```

**3. Check queen telemetry:**
```bash
# Subscribe to queen SSE stream
curl http://localhost:7833/v1/heartbeats/stream

# Look for HiveTelemetry events with workers array
# Each worker has "instance": "8080" (the port)
```

**4. Query telemetry registry (in queen code):**
```rust
let workers = telemetry_registry.get_all_workers();
for worker in workers {
    println!("Worker PID: {}, Port: {}, Model: {:?}", 
             worker.pid, worker.instance, worker.model);
}
```

---

## üìù Summary

### Current State

- ‚úÖ Worker port is in `WorkerInfo.port`
- ‚úÖ Worker port is in `ProcessStats.instance`
- ‚úÖ Hive sends worker telemetry to queen via SSE
- ‚úÖ Queen stores worker stats in `TelemetryRegistry`
- ‚úÖ Queen can query workers by port/model/GPU usage

### No Changes Needed!

The dynamic port allocation we implemented integrates seamlessly with the existing heartbeat/telemetry system. The queen already receives worker port information and can use it for scheduling decisions.

### Next Steps

1. **Test the integration** - Verify ports appear in telemetry
2. **Implement scheduling logic** - Use `TelemetryRegistry` to find workers
3. **Send inference requests** - Use worker port to construct URLs

---

**Status**: ‚úÖ READY - Dynamic ports flow to queen automatically via existing telemetry
