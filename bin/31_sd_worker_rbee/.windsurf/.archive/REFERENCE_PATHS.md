# Critical Reference Paths for SD Worker Development

**For:** All teams working on SD Worker (TEAM-391 through TEAM-401)  
**Status:** MANDATORY READING

---

## ğŸ”¥ MUST FOLLOW: Architecture Pattern

### Primary Pattern (MIRROR THIS STRUCTURE)
```
/home/vince/Projects/llama-orch/bin/30_llm_worker_rbee/
```

**Why:** The SD worker MUST mirror the LLM worker's structure for consistency.

**What to copy:**
- Module organization: `backend/`, `http/`, `bin/`
- Patterns: Request queue, generation engine, SSE streaming
- Naming conventions
- Error handling patterns
- Testing structure

**Key files to study:**
- `src/backend/mod.rs` - Backend module structure
- `src/backend/generation_engine.rs` - Background task pattern
- `src/backend/request_queue.rs` - MPSC queue pattern
- `src/http/mod.rs` - HTTP module structure
- `src/http/jobs.rs` - Job submission endpoint
- `src/http/stream.rs` - SSE streaming endpoint
- `src/http/sse.rs` - SSE utilities
- `src/bin/cpu.rs` - Binary entry point pattern

---

## ğŸ“š Working Candle Examples (STUDY THESE)

### SD 1.5/2.1/XL/Turbo Implementation
```
/home/vince/Projects/llama-orch/reference/candle/candle-examples/examples/stable-diffusion/
```

**Critical file:**
- `main.rs` - Complete working implementation

**What you'll learn:**
- How to load CLIP text encoder
- How to load UNet diffusion model
- How to load VAE decoder
- How to set up scheduler (DDIM, Euler, etc.)
- Complete text-to-image pipeline
- Image-to-image transformation
- Inpainting with masks
- Prompt encoding with tokenizer
- Latent diffusion loop
- VAE decoding to images

**Key sections to study:**
- Lines 1-250: Argument parsing and model file paths
- Lines 250-400: Model loading from HuggingFace Hub
- Lines 400-600: Text encoding with CLIP
- Lines 600-800: Diffusion loop with scheduler
- Lines 800+: VAE decoding and image saving

### SD 3/3.5 Implementation (Future Reference)
```
/home/vince/Projects/llama-orch/reference/candle/candle-examples/examples/stable-diffusion-3/
```

**What you'll learn:**
- MMDiT architecture (different from UNet)
- SD 3 Medium (2.5B params)
- SD 3.5 Large (8.1B params)
- SD 3.5 Turbo (4-step inference)

**Note:** Focus on SD 1.5/2.1/XL first. SD 3 is for future enhancement.

---

## ğŸ”§ Shared Components (DO NOT DUPLICATE)

### Shared Worker Utilities
```
/home/vince/Projects/llama-orch/bin/32_shared_worker_rbee/
```

**Already available (created by TEAM-390):**
- `src/device.rs` - Device management (CPU/CUDA/Metal)
  - `init_cpu_device()`
  - `init_cuda_device(gpu_id)`
  - `init_metal_device(gpu_id)`
  - `verify_device(device)`

- `src/heartbeat.rs` - Heartbeat system
  - `send_heartbeat_to_queen()`
  - `start_heartbeat_task()`

**Usage in SD worker:**
```rust
// In sd-worker-rbee
use shared_worker_rbee::device;

let device = device::init_cpu_device()?;
device::verify_device(&device)?;
```

**Rule:** If you need device or heartbeat functionality, use the shared crate. DO NOT duplicate code.

**Future additions:** If you create utilities that could be shared between LLM and SD workers, add them to this crate.

---

## ğŸ“‚ Directory Structure Comparison

### LLM Worker (Pattern to Follow)
```
bin/30_llm_worker_rbee/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ models/              # Model definitions
â”‚   â”‚   â”œâ”€â”€ generation_engine.rs # Background task
â”‚   â”‚   â”œâ”€â”€ request_queue.rs     # MPSC queue
â”‚   â”‚   â”œâ”€â”€ inference.rs         # Main inference
â”‚   â”‚   â””â”€â”€ mod.rs
â”‚   â”œâ”€â”€ http/
â”‚   â”‚   â”œâ”€â”€ jobs.rs              # Job submission
â”‚   â”‚   â”œâ”€â”€ stream.rs            # SSE streaming
â”‚   â”‚   â”œâ”€â”€ sse.rs               # SSE utilities
â”‚   â”‚   â”œâ”€â”€ validation.rs        # Request validation
â”‚   â”‚   â”œâ”€â”€ middleware/          # Auth, logging
â”‚   â”‚   â””â”€â”€ mod.rs
â”‚   â”œâ”€â”€ bin/
â”‚   â”‚   â”œâ”€â”€ cpu.rs               # CPU binary
â”‚   â”‚   â”œâ”€â”€ cuda.rs              # CUDA binary
â”‚   â”‚   â””â”€â”€ metal.rs             # Metal binary
â”‚   â”œâ”€â”€ lib.rs
â”‚   â”œâ”€â”€ error.rs
â”‚   â””â”€â”€ ...
â””â”€â”€ Cargo.toml
```

### SD Worker (MUST Match This Structure)
```
bin/31_sd_worker_rbee/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ models/              # SD model definitions (âœ… DONE by TEAM-390)
â”‚   â”‚   â”œâ”€â”€ generation_engine.rs # Background task (TODO)
â”‚   â”‚   â”œâ”€â”€ request_queue.rs     # MPSC queue (TODO)
â”‚   â”‚   â”œâ”€â”€ inference.rs         # SD inference (TODO)
â”‚   â”‚   â”œâ”€â”€ clip.rs              # CLIP encoder (TODO)
â”‚   â”‚   â”œâ”€â”€ vae.rs               # VAE decoder (TODO)
â”‚   â”‚   â”œâ”€â”€ scheduler.rs         # Diffusion scheduler (TODO)
â”‚   â”‚   â””â”€â”€ mod.rs               # (âœ… DONE by TEAM-390)
â”‚   â”œâ”€â”€ http/
â”‚   â”‚   â”œâ”€â”€ jobs.rs              # Job submission (TODO)
â”‚   â”‚   â”œâ”€â”€ stream.rs            # SSE streaming (TODO)
â”‚   â”‚   â”œâ”€â”€ sse.rs               # SSE utilities (TODO)
â”‚   â”‚   â”œâ”€â”€ validation.rs        # Request validation (TODO)
â”‚   â”‚   â”œâ”€â”€ middleware/          # Auth, logging (TODO)
â”‚   â”‚   â””â”€â”€ mod.rs               # (placeholder)
â”‚   â”œâ”€â”€ bin/
â”‚   â”‚   â”œâ”€â”€ cpu.rs               # (âœ… DONE by TEAM-390)
â”‚   â”‚   â”œâ”€â”€ cuda.rs              # (âœ… DONE by TEAM-390)
â”‚   â”‚   â””â”€â”€ metal.rs             # (âœ… DONE by TEAM-390)
â”‚   â”œâ”€â”€ lib.rs                   # (âœ… DONE by TEAM-390)
â”‚   â”œâ”€â”€ error.rs                 # (âœ… DONE by TEAM-390)
â”‚   â””â”€â”€ ...
â””â”€â”€ Cargo.toml                   # (âœ… DONE by TEAM-390)
```

---

## ğŸ¯ How to Use These References

### For TEAM-391 (Planning)
1. Study LLM worker structure thoroughly
2. Map LLM worker modules to SD worker equivalents
3. Use Candle examples to estimate complexity
4. Create work packages that mirror LLM worker development

### For TEAM-392+ (Implementation)
1. **Before writing ANY code:**
   - Read the corresponding LLM worker file
   - Read the Candle example code
   - Understand the pattern

2. **While implementing:**
   - Follow LLM worker patterns
   - Adapt Candle example code
   - Use shared components where available

3. **After implementing:**
   - Verify structure matches LLM worker
   - Test with Candle examples as reference
   - Document any deviations

---

## ğŸš¨ Common Mistakes to Avoid

### âŒ DON'T:
1. **Ignore LLM worker structure** - "I'll organize it differently"
2. **Reinvent device management** - "I'll write my own device init"
3. **Skip Candle examples** - "I'll figure it out myself"
4. **Create different patterns** - "HTTP endpoints should work differently"
5. **Duplicate shared code** - "I'll copy device.rs into SD worker"

### âœ… DO:
1. **Mirror LLM worker structure** - Same modules, same patterns
2. **Use shared components** - Device, heartbeat from shared crate
3. **Study Candle examples** - Working code is the best teacher
4. **Follow established patterns** - Request queue, generation engine, SSE
5. **Ask if unsure** - Better to ask than to diverge

---

## ğŸ“– Reading Order (Recommended)

### Phase 1: Understanding (Before Planning)
1. Read LLM worker README: `bin/30_llm_worker_rbee/README.md`
2. Study LLM worker structure: `bin/30_llm_worker_rbee/src/`
3. Read Candle SD example: `reference/candle/candle-examples/examples/stable-diffusion/main.rs`
4. Review shared components: `bin/32_shared_worker_rbee/src/`

### Phase 2: Planning (TEAM-391)
1. Map LLM modules to SD equivalents
2. Identify what Candle examples provide
3. Plan work packages based on LLM worker phases
4. Document dependencies

### Phase 3: Implementation (TEAM-392+)
1. Read your team's instructions
2. Study relevant LLM worker files
3. Study relevant Candle example sections
4. Implement following the patterns
5. Test against Candle examples

---

## ğŸ”— Quick Links

| Purpose | Path |
|---------|------|
| **LLM Worker (Pattern)** | `/home/vince/Projects/llama-orch/bin/30_llm_worker_rbee/` |
| **Candle SD Examples** | `/home/vince/Projects/llama-orch/reference/candle/candle-examples/examples/stable-diffusion/` |
| **Candle SD3 Examples** | `/home/vince/Projects/llama-orch/reference/candle/candle-examples/examples/stable-diffusion-3/` |
| **Shared Components** | `/home/vince/Projects/llama-orch/bin/32_shared_worker_rbee/` |
| **SD Worker (Current)** | `/home/vince/Projects/llama-orch/bin/31_sd_worker_rbee/` |

---

## âœ… Verification

Before implementing, verify you understand:
- [ ] LLM worker module structure
- [ ] Request queue pattern
- [ ] Generation engine pattern
- [ ] SSE streaming pattern
- [ ] How Candle loads SD models
- [ ] How Candle runs inference
- [ ] What shared components are available

**If you can't check all boxes, read the references again.**

---

**Remember: These references are not suggestions. They are requirements.**

**Follow the patterns. Use the examples. Don't reinvent the wheel.** ğŸ¯
