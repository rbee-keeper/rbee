# SD Worker MVP Checklist

**Date:** 2025-11-12  
**Status:** üö® CRITICAL GAPS IDENTIFIED  
**Current State:** Basic text-to-image only, missing critical features

---

## Executive Summary

**README Claims vs Reality:**

| Feature | README Says | Source Code Says | Status |
|---------|-------------|------------------|--------|
| Text-to-image | ‚úÖ Supported | ‚úÖ Implemented | ‚úÖ WORKS |
| Image-to-image | ‚úÖ Supported | ‚ùå Stub only | ‚ùå BROKEN |
| Inpainting | ‚úÖ Supported | ‚ùå Stub only | ‚ùå BROKEN |
| Multiple models | ‚úÖ SD 1.5, 2.1, XL, Turbo, SD3 | ‚ö†Ô∏è Enum exists, loading unclear | ‚ö†Ô∏è UNTESTED |
| LoRA | Not mentioned | ‚ùå No code | ‚ùå MISSING |
| ControlNet | Not mentioned | ‚ùå No code | ‚ùå MISSING |
| Streaming progress | ‚úÖ Via SSE | ‚úÖ Implemented | ‚úÖ WORKS |

**Verdict:** Worker is **NOT production ready** despite README claim. Only basic text-to-image works.

---

## üî¥ CRITICAL - Must Have for MVP

### 1. **Image-to-Image (img2img)** ‚ùå NOT IMPLEMENTED

**Current State:**
```rust
// job_router.rs line 97-104
async fn execute_image_transform(...) -> Result<JobResponse> {
    Err(anyhow!("ImageTransform not yet implemented - requires img2img pipeline"))
}
```

**What's Missing:**
- [ ] VAE encoder to convert input image to latents
- [ ] Strength parameter handling (0.0-1.0)
- [ ] Noise addition to existing latents
- [ ] Partial denoising (not full generation)

**Implementation Needed:**
```rust
// backend/generation.rs - NEW FUNCTION
pub fn image_to_image(
    config: &SamplingConfig,
    models: &ModelComponents,
    input_image: &DynamicImage,
    strength: f64,  // 0.0 = no change, 1.0 = full regeneration
    progress_callback: F,
) -> Result<DynamicImage>
```

**Estimated Effort:** 2-3 days  
**Priority:** üî¥ HIGH - Common use case (style transfer, variations)

---

### 2. **Inpainting** ‚ùå NOT IMPLEMENTED

**Current State:**
```rust
// job_router.rs line 106-113
async fn execute_inpaint(...) -> Result<JobResponse> {
    Err(anyhow!("ImageInpaint not yet implemented - requires inpainting pipeline"))
}
```

**What's Missing:**
- [ ] Mask processing (binary mask ‚Üí latent space)
- [ ] Masked latent initialization
- [ ] Inpainting-specific UNet models (V1_5Inpaint, V2Inpaint, XLInpaint)
- [ ] Mask blending in latent space

**Implementation Needed:**
```rust
// backend/generation.rs - NEW FUNCTION
pub fn inpaint(
    config: &SamplingConfig,
    models: &ModelComponents,
    input_image: &DynamicImage,
    mask: &DynamicImage,  // White = inpaint, Black = keep
    progress_callback: F,
) -> Result<DynamicImage>
```

**Note:** Inpainting models already defined in enum:
- `V1_5Inpaint` ‚Üí `stable-diffusion-v1-5/stable-diffusion-inpainting`
- `V2Inpaint` ‚Üí `stabilityai/stable-diffusion-2-inpainting`
- `XLInpaint` ‚Üí `diffusers/stable-diffusion-xl-1.0-inpainting-0.1`

**Estimated Effort:** 3-4 days  
**Priority:** üî¥ HIGH - Essential for editing workflows

---

### 3. **Model Loading Verification** ‚ö†Ô∏è UNCLEAR

**Current State:**
- Enum defines 7 model versions (V1_5, V1_5Inpaint, V2_1, V2Inpaint, XL, XLInpaint, Turbo)
- Config methods exist for each version
- **BUT:** No evidence of actual model loading tests

**What's Missing:**
- [ ] Verify all 7 models can actually load
- [ ] Test each model generates valid images
- [ ] Confirm inpainting models work differently than base models
- [ ] Test SDXL models (1024x1024 resolution)
- [ ] Test Turbo model (4-step generation)

**Tests Needed:**
```bash
# Test each model variant
cargo test --features cpu test_v1_5_generation
cargo test --features cpu test_v2_1_generation
cargo test --features cpu test_xl_generation
cargo test --features cpu test_turbo_generation
cargo test --features cpu test_inpainting_models
```

**Estimated Effort:** 1-2 days  
**Priority:** üü† MEDIUM - Need to verify claims in README

---

## üü† HIGH PRIORITY - Should Have for MVP

### 4. **LoRA Support** ‚ùå NOT IMPLEMENTED

**Current State:** No code exists for LoRA

**What's Missing:**
- [ ] LoRA weight loading from SafeTensors
- [ ] LoRA weight merging into UNet
- [ ] Multiple LoRA support (stacking)
- [ ] LoRA strength parameter (0.0-1.0)

**Why It Matters:**
- LoRA is the #1 way users customize SD models
- CivitAI has 100K+ LoRA models
- Without LoRA, worker is severely limited

**Implementation Needed:**
```rust
// backend/lora.rs - NEW FILE
pub struct LoRAWeights {
    weights: HashMap<String, Tensor>,
}

pub fn apply_lora(
    unet: &mut UNet2DConditionModel,
    lora_weights: &[LoRAWeights],
    strengths: &[f64],
) -> Result<()>
```

**Estimated Effort:** 5-7 days  
**Priority:** üü† HIGH - Critical for marketplace compatibility

---

### 5. **ControlNet Support** ‚ùå NOT IMPLEMENTED

**Current State:** No code exists for ControlNet

**What's Missing:**
- [ ] ControlNet model loading
- [ ] Conditioning image preprocessing
- [ ] ControlNet integration into UNet forward pass
- [ ] Multiple ControlNet support (pose + depth)

**Why It Matters:**
- ControlNet enables precise control (pose, depth, edges)
- Professional workflows require ControlNet
- CivitAI has thousands of ControlNet models

**Implementation Needed:**
```rust
// backend/controlnet.rs - NEW FILE
pub struct ControlNetModel {
    model: ControlNet,
    conditioning_scale: f64,
}

pub fn apply_controlnet(
    unet_output: &Tensor,
    controlnet_models: &[ControlNetModel],
    conditioning_images: &[Tensor],
) -> Result<Tensor>
```

**Estimated Effort:** 7-10 days  
**Priority:** üü† HIGH - Professional feature, high demand

---

### 6. **FLUX.1 Support** ‚úÖ CANDLE HAS IT!

**Status:** Candle already has full FLUX support!

**What's Available:**
- ‚úÖ Full FLUX implementation in `candle-transformers`
- ‚úÖ Working example in `candle-examples/examples/flux/`
- ‚úÖ Two variants: Dev (50 steps) and Schnell (4 steps)
- ‚úÖ T5 + CLIP text encoders
- ‚úÖ Quantized GGUF support

**What's Missing:**
- [ ] Add `FluxDev` and `FluxSchnell` to `SDVersion` enum
- [ ] Create `flux_loader.rs` module
- [ ] Create `flux_generation.rs` module
- [ ] Integrate with model loader
- [ ] Test FLUX generation

**Estimated Effort:** 4-6 days (just integration, not implementation)  
**Priority:** üü† HIGH - Better quality than SDXL, future-proof architecture

**Why FLUX:**
- State-of-the-art quality
- Better prompt adherence
- CivitAI already supports Flux.1 D and Flux.1 S
- Competitive advantage (most workers don't support it yet)

---

## üü° MEDIUM PRIORITY - Nice to Have

### 7. **Negative Prompts Enhancement**

**Current State:** Basic negative prompt support exists

**Improvements:**
- [ ] Negative prompt strength parameter
- [ ] Per-region negative prompts
- [ ] Negative embeddings support

**Estimated Effort:** 2-3 days  
**Priority:** üü° MEDIUM - Quality of life improvement

---

### 8. **Advanced Sampling Options**

**Current State:** Basic DDIM/Euler scheduler

**Improvements:**
- [ ] DPM++ 2M Karras scheduler
- [ ] UniPC scheduler
- [ ] DDPM scheduler
- [ ] Scheduler comparison tests

**Estimated Effort:** 3-4 days  
**Priority:** üü° MEDIUM - Power users want this

---

### 9. **Batch Generation**

**Current State:** One image at a time

**Improvements:**
- [ ] Generate multiple images in one request
- [ ] Parallel generation on multi-GPU
- [ ] Batch size optimization

**Estimated Effort:** 4-5 days  
**Priority:** üü° MEDIUM - Performance optimization

---

### 10. **Upscaling Integration**

**Current State:** No upscaling

**Improvements:**
- [ ] Real-ESRGAN integration
- [ ] SD Upscale pipeline
- [ ] Tiled upscaling for large images

**Estimated Effort:** 5-7 days  
**Priority:** üü¢ LOW - Separate service better

---

## üü¢ LOW PRIORITY - Future Enhancements

### 11. **Video Generation**

- [ ] AnimateDiff support
- [ ] Frame interpolation
- [ ] Video upscaling

**Estimated Effort:** 14-21 days  
**Priority:** üü¢ LOW - Different worker better

---

### 12. **3D Generation**

- [ ] Zero123 support
- [ ] Point-E integration
- [ ] NeRF generation

**Estimated Effort:** 21+ days  
**Priority:** üü¢ LOW - Experimental, separate worker

---

## Summary: What's Actually Needed for MVP

### Minimum Viable Product (4-6 weeks)

**Must Have (2-3 weeks):**
1. ‚úÖ Text-to-image (DONE)
2. ‚ùå Image-to-image (2-3 days)
3. ‚ùå Inpainting (3-4 days)
4. ‚ö†Ô∏è Model loading verification (1-2 days)

**Should Have (2-3 weeks):**
5. ‚ùå LoRA support (5-7 days)
6. ‚ùå ControlNet support (7-10 days)

**Total Estimated Effort:** 18-26 days of focused development

---

## Current Marketplace Compatibility (Accurate)

Based on **actual source code** (not README):

### HuggingFace
- ‚úÖ `text-to-image` task
- ‚úÖ `diffusers` library
- ‚úÖ SafeTensors format

### CivitAI
- ‚úÖ `Checkpoint` models ONLY
- ‚ùå NO LoRA (not implemented)
- ‚ùå NO ControlNet (not implemented)
- ‚ùå NO TextualInversion (not implemented)
- ‚ùå NO Hypernetwork (not implemented)

**Supported Base Models:**
- ‚úÖ SD 1.4, SD 1.5 (+ inpainting variant)
- ‚úÖ SD 2.0, SD 2.1 (+ inpainting variant)
- ‚úÖ SDXL 0.9, SDXL 1.0, SDXL Turbo (+ inpainting variant)
- ‚ùå SD 3, SD 3.5 (claimed in README but not in code)
- ‚ùå Flux.1 (not supported)
- ‚ùå Pony, Illustrious (not supported)

---

## Recommendations

### Immediate Actions (This Week)

1. **Fix README** - Remove false claims about img2img, inpainting, SD3
2. **Update Marketplace Compatibility** - Only list `Checkpoint` models
3. **Add Warning Banner** - "MVP: Text-to-image only, img2img/inpainting coming soon"

### Short Term (Next 2 Weeks)

4. **Implement img2img** - Most requested feature
5. **Implement inpainting** - Essential for editing
6. **Test all model variants** - Verify V1.5, V2.1, XL, Turbo actually work

### Medium Term (Next 4-6 Weeks)

7. **Add LoRA support** - Unlock 100K+ CivitAI models
8. **Add ControlNet support** - Professional workflows
9. **Update marketplace compatibility** - Add LoRA, ControlNet to supported types

### Long Term (2-3 Months)

10. **SD3 support** - Latest architecture
11. **Advanced schedulers** - DPM++, UniPC
12. **Batch generation** - Performance optimization

---

## Testing Checklist

Before claiming "Production Ready":

- [ ] Text-to-image generates valid images
- [ ] Image-to-image works with various strength values
- [ ] Inpainting correctly masks regions
- [ ] All 7 model variants load successfully
- [ ] LoRA weights apply correctly
- [ ] ControlNet conditioning works
- [ ] Streaming progress reports accurately
- [ ] Error handling for invalid inputs
- [ ] Memory usage stays within limits
- [ ] Generation completes in reasonable time

**Current Status:** 1/10 tests pass ‚ùå

---

**Created by:** TEAM-486  
**Based on:** Actual source code analysis, not documentation  
**Verdict:** Worker needs 4-6 weeks of work before true MVP status
